{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f837d3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "090d129d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of distict words in Shahnameh: 18008\n"
     ]
    }
   ],
   "source": [
    "Poem = []\n",
    "with open('ferdousi.txt', 'r', encoding = 'utf8') as f:\n",
    "    for _ in range(99218):\n",
    "        Poem.append(f.readline())\n",
    "\n",
    "Poem_Modif = [p[0:-1] for p in Poem[2:]]\n",
    "\n",
    "\n",
    "Dict = []\n",
    "Len_Verse = []\n",
    "for p in Poem_Modif:\n",
    "    w_token = word_tokenize(p)\n",
    "    Dict.extend(w_token)\n",
    "    Len_Verse.append(len(w_token))\n",
    "Dict = list(set(Dict))\n",
    "Add1 = ['<شروع>', '<خالی>', '.']\n",
    "Add1.extend(Dict)\n",
    "Dict = Add1\n",
    "\n",
    "print(f'Number of distict words in Shahnameh: {len(Dict)-2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "818f5b2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<شروع>', 'به', 'نام', 'خداوند', 'جان', 'و', 'خرد', '<خالی>', '<خالی>', '<خالی>', '<خالی>', '<خالی>', '.']\n",
      "[0, 595, 10732, 1680, 1647, 6476, 1052, 1, 1, 1, 1, 1, 2]\n"
     ]
    }
   ],
   "source": [
    "# Word to Index\n",
    "Pin = Poem_Modif[0]\n",
    "Pin = word_tokenize(Pin)\n",
    "if len(Pin) < 11:\n",
    "    for _ in range(11 - len(Pin)):\n",
    "        Pin.append('<خالی>')\n",
    "string = '<شروع>'\n",
    "Pin.insert(0, string)\n",
    "Pin.insert(len(Pin), '.')\n",
    "Pin_idx = [Dict.index(p) for p in Pin]\n",
    "print(Pin)\n",
    "print(Pin_idx)\n",
    "#print(word_tokenize(Poem_Modif[0]), Len_Verse[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c047302c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, Poem, Dictionary, Len_Verse):\n",
    "        self.poem = Poem\n",
    "        self.Dict = Dictionary\n",
    "        self.Lverse = Len_Verse\n",
    "        self.Lmax = max(self.Lverse)\n",
    "    def __len__(self):\n",
    "        return int(len(self.Lverse)/2)\n",
    "    def __getitem__(self, idx):\n",
    "        Pin = self.poem[2*idx]\n",
    "        Pin = word_tokenize(Pin)\n",
    "        if len(Pin) < self.Lmax:\n",
    "            for _ in range(self.Lmax - len(Pin)):\n",
    "                Pin.append('<خالی>')\n",
    "        string = '<شروع>'\n",
    "        Pin.insert(0, string)\n",
    "        Pin.insert(len(Pin), '.')\n",
    "        Pin_idx = [self.Dict.index(p) for p in Pin]\n",
    "        \n",
    "        Pout = self.poem[2*idx + 1]\n",
    "        Pout = word_tokenize(Pout)\n",
    "        if len(Pout) < self.Lmax:\n",
    "            for _ in range(self.Lmax - len(Pout)):\n",
    "                Pout.append('<خالی>')\n",
    "        string = '<شروع>'\n",
    "        Pout.insert(0, string)\n",
    "        Pout.insert(len(Pout), '.')\n",
    "        Pout_idx = [self.Dict.index(p) for p in Pout]\n",
    "        return torch.LongTensor(Pin_idx), torch.LongTensor(Pout_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a7fcdeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN_Model(nn.Module):\n",
    "    def __init__(self, LDict, Lverse):\n",
    "        super(RNN_Model, self).__init__()\n",
    "        self.embed_dim = 200\n",
    "        self.hid_size = 500\n",
    "        self.Lverse = Lverse\n",
    "        self.embedding = nn.Embedding(num_embeddings= LDict, embedding_dim= self.embed_dim)\n",
    "        self.lstm = nn.LSTM(input_size = self.embed_dim, num_layers = 2, hidden_size = self.hid_size,\\\n",
    "                                   batch_first = True, bidirectional = False)\n",
    "        self.linear = nn.Linear(in_features = 1*self.hid_size, out_features= LDict)\n",
    "    def forward(self, X):\n",
    "        word_idx = torch.cat((X[0][:, 1:], X[1][:, 0:-1]), dim = -1)\n",
    "        word_embed = self.embedding(word_idx)\n",
    "        hout, _ = self.lstm(word_embed)\n",
    "        logits = self.linear(hout)\n",
    "        return logits[:, self.Lverse+1:, :]\n",
    "\n",
    "class GRU_Model(nn.Module):\n",
    "    def __init__(self, LDict, Lverse):\n",
    "        super(GRU_Model, self).__init__()\n",
    "        self.embed_dim = 200\n",
    "        self.hid_size = 500\n",
    "        self.Lverse = Lverse\n",
    "        self.embedding = nn.Embedding(num_embeddings= LDict, embedding_dim= self.embed_dim)\n",
    "        self.gru = nn.GRU(input_size = self.embed_dim, num_layers = 2, hidden_size = self.hid_size,\\\n",
    "                                   batch_first = True, bidirectional = False)\n",
    "        self.linear = nn.Linear(in_features = 1*self.hid_size, out_features= LDict)\n",
    "    def forward(self, X):\n",
    "        word_idx = torch.cat((X[0][:, 1:], X[1][:, 0:-1]), dim = -1)\n",
    "        word_embed = self.embedding(word_idx)\n",
    "        hout, _ = self.gru(word_embed)\n",
    "        logits = self.linear(hout)\n",
    "        return logits[:, self.Lverse+1:, :]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e15b02b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49608 39687 9921\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "All_Data = MyDataset(Poem_Modif, Dict, Len_Verse);\n",
    "SplitData = random_split(All_Data, [0.80, 0.20])\n",
    "Train = SplitData[0]\n",
    "Test = SplitData[1]\n",
    "print(len(All_Data), len(Train), len(Test))\n",
    "batch_size = 64\n",
    "train_dataloader = DataLoader(Train, batch_size = batch_size, shuffle = True)\n",
    "test_dataloader = DataLoader(Test, batch_size = batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ea116350",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lstm = RNN_Model(len(Dict), max(Len_Verse))\n",
    "device = 'cuda' if torch.cuda.is_available else 'cpu'\n",
    "model_lstm.to(device)\n",
    "optimizer_lstm = torch.optim.Adam(model_lstm.parameters(), lr = 1e-3)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "writer_lstm = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2e3d52c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gru = GRU_Model(len(Dict), max(Len_Verse))\n",
    "model_gru.to(device)\n",
    "optimizer_gru = torch.optim.Adam(model_gru.parameters(), lr = 1e-3)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "writer_gru = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5a904e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(Model, Optimizer, Loss_Func, dataloader, writer, kep, model_name):\n",
    "    LD = len(dataloader.dataset)\n",
    "    for i, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        ypred = Model([X, y])\n",
    "        ypred = ypred.permute(0, 2, 1)\n",
    "        yy = y[:, 1:]\n",
    "        loss = Loss_Func(ypred, yy)\n",
    "        Optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        Optimizer.step()\n",
    "        if i % 50 == 0:\n",
    "            print(f'loss = {loss.item():5f}     [{i*batch_size:5}\\{LD:5}]')\n",
    "            writer.add_scalar(f'Loss/train {model_name}', loss, i + kep*len(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "05cb56cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0-----------------------------------------\n",
      "loss = 9.804275     [    0\\39687]\n",
      "loss = 3.911157     [ 3200\\39687]\n",
      "loss = 3.683077     [ 6400\\39687]\n",
      "loss = 3.357572     [ 9600\\39687]\n",
      "loss = 3.469652     [12800\\39687]\n",
      "loss = 3.357467     [16000\\39687]\n",
      "loss = 3.294295     [19200\\39687]\n",
      "loss = 3.328545     [22400\\39687]\n",
      "loss = 3.275915     [25600\\39687]\n",
      "loss = 3.345386     [28800\\39687]\n",
      "loss = 3.214770     [32000\\39687]\n",
      "loss = 3.223907     [35200\\39687]\n",
      "loss = 3.211159     [38400\\39687]\n",
      "\n",
      "Epoch: 1-----------------------------------------\n",
      "loss = 3.180510     [    0\\39687]\n",
      "loss = 3.116836     [ 3200\\39687]\n",
      "loss = 3.072455     [ 6400\\39687]\n",
      "loss = 3.076463     [ 9600\\39687]\n",
      "loss = 2.968444     [12800\\39687]\n",
      "loss = 2.936721     [16000\\39687]\n",
      "loss = 2.965333     [19200\\39687]\n",
      "loss = 3.036682     [22400\\39687]\n",
      "loss = 2.998941     [25600\\39687]\n",
      "loss = 2.886612     [28800\\39687]\n",
      "loss = 2.891507     [32000\\39687]\n",
      "loss = 3.082515     [35200\\39687]\n",
      "loss = 2.977462     [38400\\39687]\n",
      "\n",
      "Epoch: 2-----------------------------------------\n",
      "loss = 2.824340     [    0\\39687]\n",
      "loss = 3.005486     [ 3200\\39687]\n",
      "loss = 2.796821     [ 6400\\39687]\n",
      "loss = 2.866821     [ 9600\\39687]\n",
      "loss = 2.841947     [12800\\39687]\n",
      "loss = 2.898453     [16000\\39687]\n",
      "loss = 2.752212     [19200\\39687]\n",
      "loss = 2.827546     [22400\\39687]\n",
      "loss = 2.764764     [25600\\39687]\n",
      "loss = 2.800475     [28800\\39687]\n",
      "loss = 2.789154     [32000\\39687]\n",
      "loss = 2.801210     [35200\\39687]\n",
      "loss = 2.751869     [38400\\39687]\n",
      "\n",
      "Epoch: 3-----------------------------------------\n",
      "loss = 2.709923     [    0\\39687]\n",
      "loss = 2.740929     [ 3200\\39687]\n",
      "loss = 2.601579     [ 6400\\39687]\n",
      "loss = 2.727619     [ 9600\\39687]\n",
      "loss = 2.743955     [12800\\39687]\n",
      "loss = 2.686870     [16000\\39687]\n",
      "loss = 2.629757     [19200\\39687]\n",
      "loss = 2.674134     [22400\\39687]\n",
      "loss = 2.762758     [25600\\39687]\n",
      "loss = 2.651081     [28800\\39687]\n",
      "loss = 2.584432     [32000\\39687]\n",
      "loss = 2.597918     [35200\\39687]\n",
      "loss = 2.602518     [38400\\39687]\n",
      "\n",
      "Epoch: 4-----------------------------------------\n",
      "loss = 2.521044     [    0\\39687]\n",
      "loss = 2.374357     [ 3200\\39687]\n",
      "loss = 2.428769     [ 6400\\39687]\n",
      "loss = 2.568691     [ 9600\\39687]\n",
      "loss = 2.386820     [12800\\39687]\n",
      "loss = 2.439790     [16000\\39687]\n",
      "loss = 2.579720     [19200\\39687]\n",
      "loss = 2.438031     [22400\\39687]\n",
      "loss = 2.433014     [25600\\39687]\n",
      "loss = 2.498594     [28800\\39687]\n",
      "loss = 2.470120     [32000\\39687]\n",
      "loss = 2.370589     [35200\\39687]\n",
      "loss = 2.415037     [38400\\39687]\n",
      "\n",
      "Epoch: 5-----------------------------------------\n",
      "loss = 2.289446     [    0\\39687]\n",
      "loss = 2.270771     [ 3200\\39687]\n",
      "loss = 2.351784     [ 6400\\39687]\n",
      "loss = 2.331897     [ 9600\\39687]\n",
      "loss = 2.275745     [12800\\39687]\n",
      "loss = 2.188514     [16000\\39687]\n",
      "loss = 2.282961     [19200\\39687]\n",
      "loss = 2.203044     [22400\\39687]\n",
      "loss = 2.178066     [25600\\39687]\n",
      "loss = 2.287883     [28800\\39687]\n",
      "loss = 2.383258     [32000\\39687]\n",
      "loss = 2.317631     [35200\\39687]\n",
      "loss = 2.269285     [38400\\39687]\n",
      "\n",
      "Epoch: 6-----------------------------------------\n",
      "loss = 2.075801     [    0\\39687]\n",
      "loss = 2.195541     [ 3200\\39687]\n",
      "loss = 2.015900     [ 6400\\39687]\n",
      "loss = 2.094672     [ 9600\\39687]\n",
      "loss = 2.153466     [12800\\39687]\n",
      "loss = 2.121080     [16000\\39687]\n",
      "loss = 2.050330     [19200\\39687]\n",
      "loss = 1.963923     [22400\\39687]\n",
      "loss = 2.115814     [25600\\39687]\n",
      "loss = 2.104280     [28800\\39687]\n",
      "loss = 2.106494     [32000\\39687]\n",
      "loss = 2.062793     [35200\\39687]\n",
      "loss = 2.120674     [38400\\39687]\n",
      "\n",
      "Epoch: 7-----------------------------------------\n",
      "loss = 1.927724     [    0\\39687]\n",
      "loss = 1.913913     [ 3200\\39687]\n",
      "loss = 1.827338     [ 6400\\39687]\n",
      "loss = 1.894342     [ 9600\\39687]\n",
      "loss = 1.805487     [12800\\39687]\n",
      "loss = 1.988005     [16000\\39687]\n",
      "loss = 1.977599     [19200\\39687]\n",
      "loss = 1.890722     [22400\\39687]\n",
      "loss = 1.837460     [25600\\39687]\n",
      "loss = 1.921939     [28800\\39687]\n",
      "loss = 2.004165     [32000\\39687]\n",
      "loss = 1.868018     [35200\\39687]\n",
      "loss = 1.874761     [38400\\39687]\n",
      "\n",
      "Epoch: 8-----------------------------------------\n",
      "loss = 1.751206     [    0\\39687]\n",
      "loss = 1.704888     [ 3200\\39687]\n",
      "loss = 1.633772     [ 6400\\39687]\n",
      "loss = 1.667077     [ 9600\\39687]\n",
      "loss = 1.661325     [12800\\39687]\n",
      "loss = 1.762413     [16000\\39687]\n",
      "loss = 1.825457     [19200\\39687]\n",
      "loss = 1.691734     [22400\\39687]\n",
      "loss = 1.707562     [25600\\39687]\n",
      "loss = 1.861011     [28800\\39687]\n",
      "loss = 1.625074     [32000\\39687]\n",
      "loss = 1.805692     [35200\\39687]\n",
      "loss = 1.885679     [38400\\39687]\n",
      "\n",
      "Epoch: 9-----------------------------------------\n",
      "loss = 1.537512     [    0\\39687]\n",
      "loss = 1.587618     [ 3200\\39687]\n",
      "loss = 1.551659     [ 6400\\39687]\n",
      "loss = 1.443576     [ 9600\\39687]\n",
      "loss = 1.575015     [12800\\39687]\n",
      "loss = 1.630492     [16000\\39687]\n",
      "loss = 1.608614     [19200\\39687]\n",
      "loss = 1.504436     [22400\\39687]\n",
      "loss = 1.577206     [25600\\39687]\n",
      "loss = 1.621130     [28800\\39687]\n",
      "loss = 1.555980     [32000\\39687]\n",
      "loss = 1.631637     [35200\\39687]\n",
      "loss = 1.516599     [38400\\39687]\n",
      "\n",
      "Epoch: 10-----------------------------------------\n",
      "loss = 1.385620     [    0\\39687]\n",
      "loss = 1.322548     [ 3200\\39687]\n",
      "loss = 1.423448     [ 6400\\39687]\n",
      "loss = 1.407010     [ 9600\\39687]\n",
      "loss = 1.380211     [12800\\39687]\n",
      "loss = 1.376534     [16000\\39687]\n",
      "loss = 1.358537     [19200\\39687]\n",
      "loss = 1.538976     [22400\\39687]\n",
      "loss = 1.365427     [25600\\39687]\n",
      "loss = 1.419134     [28800\\39687]\n",
      "loss = 1.521910     [32000\\39687]\n",
      "loss = 1.537917     [35200\\39687]\n",
      "loss = 1.435373     [38400\\39687]\n",
      "\n",
      "Epoch: 11-----------------------------------------\n",
      "loss = 1.300022     [    0\\39687]\n",
      "loss = 1.186103     [ 3200\\39687]\n",
      "loss = 1.264654     [ 6400\\39687]\n",
      "loss = 1.248080     [ 9600\\39687]\n",
      "loss = 1.272684     [12800\\39687]\n",
      "loss = 1.240210     [16000\\39687]\n",
      "loss = 1.341475     [19200\\39687]\n",
      "loss = 1.195237     [22400\\39687]\n",
      "loss = 1.253553     [25600\\39687]\n",
      "loss = 1.276429     [28800\\39687]\n",
      "loss = 1.335010     [32000\\39687]\n",
      "loss = 1.325081     [35200\\39687]\n",
      "loss = 1.311647     [38400\\39687]\n",
      "\n",
      "Epoch: 12-----------------------------------------\n",
      "loss = 1.153681     [    0\\39687]\n",
      "loss = 1.008581     [ 3200\\39687]\n",
      "loss = 1.143006     [ 6400\\39687]\n",
      "loss = 1.110905     [ 9600\\39687]\n",
      "loss = 1.144933     [12800\\39687]\n",
      "loss = 1.156249     [16000\\39687]\n",
      "loss = 1.143575     [19200\\39687]\n",
      "loss = 1.118125     [22400\\39687]\n",
      "loss = 1.168971     [25600\\39687]\n",
      "loss = 1.110620     [28800\\39687]\n",
      "loss = 1.137576     [32000\\39687]\n",
      "loss = 1.152400     [35200\\39687]\n",
      "loss = 1.126179     [38400\\39687]\n",
      "\n",
      "Epoch: 13-----------------------------------------\n",
      "loss = 0.942736     [    0\\39687]\n",
      "loss = 0.978168     [ 3200\\39687]\n",
      "loss = 1.035113     [ 6400\\39687]\n",
      "loss = 1.023974     [ 9600\\39687]\n",
      "loss = 1.047713     [12800\\39687]\n",
      "loss = 1.019617     [16000\\39687]\n",
      "loss = 1.023382     [19200\\39687]\n",
      "loss = 1.043963     [22400\\39687]\n",
      "loss = 1.058091     [25600\\39687]\n",
      "loss = 1.022641     [28800\\39687]\n",
      "loss = 1.060890     [32000\\39687]\n",
      "loss = 1.059583     [35200\\39687]\n",
      "loss = 1.123222     [38400\\39687]\n",
      "\n",
      "Epoch: 14-----------------------------------------\n",
      "loss = 0.818812     [    0\\39687]\n",
      "loss = 0.874243     [ 3200\\39687]\n",
      "loss = 0.943532     [ 6400\\39687]\n",
      "loss = 0.881502     [ 9600\\39687]\n",
      "loss = 0.855034     [12800\\39687]\n",
      "loss = 0.792246     [16000\\39687]\n",
      "loss = 0.896035     [19200\\39687]\n",
      "loss = 0.913746     [22400\\39687]\n",
      "loss = 0.934079     [25600\\39687]\n",
      "loss = 1.013573     [28800\\39687]\n",
      "loss = 0.965051     [32000\\39687]\n",
      "loss = 0.948237     [35200\\39687]\n",
      "loss = 0.915967     [38400\\39687]\n",
      "\n",
      "Epoch: 15-----------------------------------------\n",
      "loss = 0.782736     [    0\\39687]\n",
      "loss = 0.754530     [ 3200\\39687]\n",
      "loss = 0.776723     [ 6400\\39687]\n",
      "loss = 0.782876     [ 9600\\39687]\n",
      "loss = 0.764621     [12800\\39687]\n",
      "loss = 0.771158     [16000\\39687]\n",
      "loss = 0.826862     [19200\\39687]\n",
      "loss = 0.809404     [22400\\39687]\n",
      "loss = 0.809929     [25600\\39687]\n",
      "loss = 0.813799     [28800\\39687]\n",
      "loss = 0.854588     [32000\\39687]\n",
      "loss = 0.834297     [35200\\39687]\n",
      "loss = 0.777530     [38400\\39687]\n",
      "\n",
      "Epoch: 16-----------------------------------------\n",
      "loss = 0.600687     [    0\\39687]\n",
      "loss = 0.641799     [ 3200\\39687]\n",
      "loss = 0.611556     [ 6400\\39687]\n",
      "loss = 0.610291     [ 9600\\39687]\n",
      "loss = 0.676566     [12800\\39687]\n",
      "loss = 0.625778     [16000\\39687]\n",
      "loss = 0.732726     [19200\\39687]\n",
      "loss = 0.688941     [22400\\39687]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.652661     [25600\\39687]\n",
      "loss = 0.705678     [28800\\39687]\n",
      "loss = 0.711845     [32000\\39687]\n",
      "loss = 0.692725     [35200\\39687]\n",
      "loss = 0.739972     [38400\\39687]\n",
      "\n",
      "Epoch: 17-----------------------------------------\n",
      "loss = 0.517230     [    0\\39687]\n",
      "loss = 0.496532     [ 3200\\39687]\n",
      "loss = 0.595971     [ 6400\\39687]\n",
      "loss = 0.506773     [ 9600\\39687]\n",
      "loss = 0.539782     [12800\\39687]\n",
      "loss = 0.560034     [16000\\39687]\n",
      "loss = 0.587169     [19200\\39687]\n",
      "loss = 0.548896     [22400\\39687]\n",
      "loss = 0.619668     [25600\\39687]\n",
      "loss = 0.579098     [28800\\39687]\n",
      "loss = 0.616159     [32000\\39687]\n",
      "loss = 0.629029     [35200\\39687]\n",
      "loss = 0.597161     [38400\\39687]\n",
      "\n",
      "Epoch: 18-----------------------------------------\n",
      "loss = 0.431959     [    0\\39687]\n",
      "loss = 0.432603     [ 3200\\39687]\n",
      "loss = 0.438615     [ 6400\\39687]\n",
      "loss = 0.436540     [ 9600\\39687]\n",
      "loss = 0.458717     [12800\\39687]\n",
      "loss = 0.473055     [16000\\39687]\n",
      "loss = 0.511867     [19200\\39687]\n",
      "loss = 0.511793     [22400\\39687]\n",
      "loss = 0.470994     [25600\\39687]\n",
      "loss = 0.518345     [28800\\39687]\n",
      "loss = 0.538038     [32000\\39687]\n",
      "loss = 0.492295     [35200\\39687]\n",
      "loss = 0.526119     [38400\\39687]\n",
      "\n",
      "Epoch: 19-----------------------------------------\n",
      "loss = 0.366179     [    0\\39687]\n",
      "loss = 0.416388     [ 3200\\39687]\n",
      "loss = 0.362558     [ 6400\\39687]\n",
      "loss = 0.358713     [ 9600\\39687]\n",
      "loss = 0.376058     [12800\\39687]\n",
      "loss = 0.358782     [16000\\39687]\n",
      "loss = 0.381749     [19200\\39687]\n",
      "loss = 0.399514     [22400\\39687]\n",
      "loss = 0.367329     [25600\\39687]\n",
      "loss = 0.435325     [28800\\39687]\n",
      "loss = 0.449095     [32000\\39687]\n",
      "loss = 0.455228     [35200\\39687]\n",
      "loss = 0.471533     [38400\\39687]\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "for k in range(20):\n",
    "    print(f'\\nEpoch: {k}-----------------------------------------')\n",
    "    model_lstm.train()\n",
    "    train_loop(model_lstm, optimizer_lstm, loss_func, train_dataloader, writer_lstm, k, 'LSTM')\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b77b3ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0-----------------------------------------\n",
      "loss = 9.797395     [    0\\39687]\n",
      "loss = 3.745973     [ 3200\\39687]\n",
      "loss = 3.566846     [ 6400\\39687]\n",
      "loss = 3.625413     [ 9600\\39687]\n",
      "loss = 3.370488     [12800\\39687]\n",
      "loss = 3.228398     [16000\\39687]\n",
      "loss = 3.447102     [19200\\39687]\n",
      "loss = 3.175660     [22400\\39687]\n",
      "loss = 3.125396     [25600\\39687]\n",
      "loss = 3.242763     [28800\\39687]\n",
      "loss = 3.100804     [32000\\39687]\n",
      "loss = 3.239866     [35200\\39687]\n",
      "loss = 3.004937     [38400\\39687]\n",
      "\n",
      "Epoch: 1-----------------------------------------\n",
      "loss = 2.773254     [    0\\39687]\n",
      "loss = 2.723202     [ 3200\\39687]\n",
      "loss = 2.764926     [ 6400\\39687]\n",
      "loss = 2.839546     [ 9600\\39687]\n",
      "loss = 2.843634     [12800\\39687]\n",
      "loss = 2.833717     [16000\\39687]\n",
      "loss = 2.663848     [19200\\39687]\n",
      "loss = 2.602902     [22400\\39687]\n",
      "loss = 2.642845     [25600\\39687]\n",
      "loss = 2.800781     [28800\\39687]\n",
      "loss = 2.660796     [32000\\39687]\n",
      "loss = 2.517396     [35200\\39687]\n",
      "loss = 2.749510     [38400\\39687]\n",
      "\n",
      "Epoch: 2-----------------------------------------\n",
      "loss = 2.253891     [    0\\39687]\n",
      "loss = 2.206292     [ 3200\\39687]\n",
      "loss = 2.279496     [ 6400\\39687]\n",
      "loss = 2.313021     [ 9600\\39687]\n",
      "loss = 2.338125     [12800\\39687]\n",
      "loss = 2.391932     [16000\\39687]\n",
      "loss = 2.268915     [19200\\39687]\n",
      "loss = 2.277097     [22400\\39687]\n",
      "loss = 2.293934     [25600\\39687]\n",
      "loss = 2.370692     [28800\\39687]\n",
      "loss = 2.282568     [32000\\39687]\n",
      "loss = 2.282360     [35200\\39687]\n",
      "loss = 2.378785     [38400\\39687]\n",
      "\n",
      "Epoch: 3-----------------------------------------\n",
      "loss = 1.884598     [    0\\39687]\n",
      "loss = 1.880462     [ 3200\\39687]\n",
      "loss = 2.010354     [ 6400\\39687]\n",
      "loss = 1.993068     [ 9600\\39687]\n",
      "loss = 2.006900     [12800\\39687]\n",
      "loss = 1.900310     [16000\\39687]\n",
      "loss = 1.934244     [19200\\39687]\n",
      "loss = 1.960638     [22400\\39687]\n",
      "loss = 1.974008     [25600\\39687]\n",
      "loss = 1.953725     [28800\\39687]\n",
      "loss = 1.954435     [32000\\39687]\n",
      "loss = 2.032356     [35200\\39687]\n",
      "loss = 1.895788     [38400\\39687]\n",
      "\n",
      "Epoch: 4-----------------------------------------\n",
      "loss = 1.594610     [    0\\39687]\n",
      "loss = 1.541307     [ 3200\\39687]\n",
      "loss = 1.609842     [ 6400\\39687]\n",
      "loss = 1.607296     [ 9600\\39687]\n",
      "loss = 1.698741     [12800\\39687]\n",
      "loss = 1.473436     [16000\\39687]\n",
      "loss = 1.634233     [19200\\39687]\n",
      "loss = 1.602168     [22400\\39687]\n",
      "loss = 1.615941     [25600\\39687]\n",
      "loss = 1.703204     [28800\\39687]\n",
      "loss = 1.645526     [32000\\39687]\n",
      "loss = 1.756184     [35200\\39687]\n",
      "loss = 1.756383     [38400\\39687]\n",
      "\n",
      "Epoch: 5-----------------------------------------\n",
      "loss = 1.321720     [    0\\39687]\n",
      "loss = 1.234888     [ 3200\\39687]\n",
      "loss = 1.359241     [ 6400\\39687]\n",
      "loss = 1.309517     [ 9600\\39687]\n",
      "loss = 1.383391     [12800\\39687]\n",
      "loss = 1.257541     [16000\\39687]\n",
      "loss = 1.362904     [19200\\39687]\n",
      "loss = 1.267279     [22400\\39687]\n",
      "loss = 1.366205     [25600\\39687]\n",
      "loss = 1.353545     [28800\\39687]\n",
      "loss = 1.334171     [32000\\39687]\n",
      "loss = 1.336212     [35200\\39687]\n",
      "loss = 1.514036     [38400\\39687]\n",
      "\n",
      "Epoch: 6-----------------------------------------\n",
      "loss = 0.998102     [    0\\39687]\n",
      "loss = 1.048672     [ 3200\\39687]\n",
      "loss = 0.992597     [ 6400\\39687]\n",
      "loss = 1.115634     [ 9600\\39687]\n",
      "loss = 1.053799     [12800\\39687]\n",
      "loss = 1.111876     [16000\\39687]\n",
      "loss = 1.185413     [19200\\39687]\n",
      "loss = 1.143849     [22400\\39687]\n",
      "loss = 1.065240     [25600\\39687]\n",
      "loss = 1.117148     [28800\\39687]\n",
      "loss = 1.109817     [32000\\39687]\n",
      "loss = 1.127776     [35200\\39687]\n",
      "loss = 1.215929     [38400\\39687]\n",
      "\n",
      "Epoch: 7-----------------------------------------\n",
      "loss = 0.796407     [    0\\39687]\n",
      "loss = 0.848030     [ 3200\\39687]\n",
      "loss = 0.821913     [ 6400\\39687]\n",
      "loss = 0.810428     [ 9600\\39687]\n",
      "loss = 0.892189     [12800\\39687]\n",
      "loss = 0.913597     [16000\\39687]\n",
      "loss = 0.830778     [19200\\39687]\n",
      "loss = 0.979682     [22400\\39687]\n",
      "loss = 0.940892     [25600\\39687]\n",
      "loss = 0.913613     [28800\\39687]\n",
      "loss = 0.918908     [32000\\39687]\n",
      "loss = 0.929691     [35200\\39687]\n",
      "loss = 1.082241     [38400\\39687]\n",
      "\n",
      "Epoch: 8-----------------------------------------\n",
      "loss = 0.608830     [    0\\39687]\n",
      "loss = 0.654009     [ 3200\\39687]\n",
      "loss = 0.644938     [ 6400\\39687]\n",
      "loss = 0.741991     [ 9600\\39687]\n",
      "loss = 0.771465     [12800\\39687]\n",
      "loss = 0.732548     [16000\\39687]\n",
      "loss = 0.709206     [19200\\39687]\n",
      "loss = 0.647057     [22400\\39687]\n",
      "loss = 0.630201     [25600\\39687]\n",
      "loss = 0.772631     [28800\\39687]\n",
      "loss = 0.706020     [32000\\39687]\n",
      "loss = 0.755931     [35200\\39687]\n",
      "loss = 0.738873     [38400\\39687]\n",
      "\n",
      "Epoch: 9-----------------------------------------\n",
      "loss = 0.475037     [    0\\39687]\n",
      "loss = 0.454425     [ 3200\\39687]\n",
      "loss = 0.520188     [ 6400\\39687]\n",
      "loss = 0.522885     [ 9600\\39687]\n",
      "loss = 0.542981     [12800\\39687]\n",
      "loss = 0.603617     [16000\\39687]\n",
      "loss = 0.508999     [19200\\39687]\n",
      "loss = 0.625628     [22400\\39687]\n",
      "loss = 0.609821     [25600\\39687]\n",
      "loss = 0.582046     [28800\\39687]\n",
      "loss = 0.583176     [32000\\39687]\n",
      "loss = 0.591322     [35200\\39687]\n",
      "loss = 0.638866     [38400\\39687]\n",
      "\n",
      "Epoch: 10-----------------------------------------\n",
      "loss = 0.309997     [    0\\39687]\n",
      "loss = 0.391508     [ 3200\\39687]\n",
      "loss = 0.395303     [ 6400\\39687]\n",
      "loss = 0.373273     [ 9600\\39687]\n",
      "loss = 0.410329     [12800\\39687]\n",
      "loss = 0.426800     [16000\\39687]\n",
      "loss = 0.431351     [19200\\39687]\n",
      "loss = 0.385076     [22400\\39687]\n",
      "loss = 0.410819     [25600\\39687]\n",
      "loss = 0.435353     [28800\\39687]\n",
      "loss = 0.444636     [32000\\39687]\n",
      "loss = 0.492593     [35200\\39687]\n",
      "loss = 0.468599     [38400\\39687]\n",
      "\n",
      "Epoch: 11-----------------------------------------\n",
      "loss = 0.288537     [    0\\39687]\n",
      "loss = 0.205251     [ 3200\\39687]\n",
      "loss = 0.260586     [ 6400\\39687]\n",
      "loss = 0.275281     [ 9600\\39687]\n",
      "loss = 0.301432     [12800\\39687]\n",
      "loss = 0.302114     [16000\\39687]\n",
      "loss = 0.280262     [19200\\39687]\n",
      "loss = 0.299189     [22400\\39687]\n",
      "loss = 0.331938     [25600\\39687]\n",
      "loss = 0.333698     [28800\\39687]\n",
      "loss = 0.372190     [32000\\39687]\n",
      "loss = 0.374099     [35200\\39687]\n",
      "loss = 0.392299     [38400\\39687]\n",
      "\n",
      "Epoch: 12-----------------------------------------\n",
      "loss = 0.186937     [    0\\39687]\n",
      "loss = 0.187326     [ 3200\\39687]\n",
      "loss = 0.191185     [ 6400\\39687]\n",
      "loss = 0.213359     [ 9600\\39687]\n",
      "loss = 0.215656     [12800\\39687]\n",
      "loss = 0.171120     [16000\\39687]\n",
      "loss = 0.182764     [19200\\39687]\n",
      "loss = 0.227962     [22400\\39687]\n",
      "loss = 0.214384     [25600\\39687]\n",
      "loss = 0.255555     [28800\\39687]\n",
      "loss = 0.271017     [32000\\39687]\n",
      "loss = 0.284473     [35200\\39687]\n",
      "loss = 0.306844     [38400\\39687]\n",
      "\n",
      "Epoch: 13-----------------------------------------\n",
      "loss = 0.155969     [    0\\39687]\n",
      "loss = 0.154535     [ 3200\\39687]\n",
      "loss = 0.131947     [ 6400\\39687]\n",
      "loss = 0.138131     [ 9600\\39687]\n",
      "loss = 0.102320     [12800\\39687]\n",
      "loss = 0.142227     [16000\\39687]\n",
      "loss = 0.201597     [19200\\39687]\n",
      "loss = 0.146862     [22400\\39687]\n",
      "loss = 0.185753     [25600\\39687]\n",
      "loss = 0.213512     [28800\\39687]\n",
      "loss = 0.203342     [32000\\39687]\n",
      "loss = 0.195223     [35200\\39687]\n",
      "loss = 0.213611     [38400\\39687]\n",
      "\n",
      "Epoch: 14-----------------------------------------\n",
      "loss = 0.089728     [    0\\39687]\n",
      "loss = 0.111906     [ 3200\\39687]\n",
      "loss = 0.149817     [ 6400\\39687]\n",
      "loss = 0.141315     [ 9600\\39687]\n",
      "loss = 0.116648     [12800\\39687]\n",
      "loss = 0.128233     [16000\\39687]\n",
      "loss = 0.134507     [19200\\39687]\n",
      "loss = 0.121679     [22400\\39687]\n",
      "loss = 0.146182     [25600\\39687]\n",
      "loss = 0.172127     [28800\\39687]\n",
      "loss = 0.141673     [32000\\39687]\n",
      "loss = 0.157580     [35200\\39687]\n",
      "loss = 0.186013     [38400\\39687]\n",
      "\n",
      "Epoch: 15-----------------------------------------\n",
      "loss = 0.084363     [    0\\39687]\n",
      "loss = 0.119513     [ 3200\\39687]\n",
      "loss = 0.078339     [ 6400\\39687]\n",
      "loss = 0.083860     [ 9600\\39687]\n",
      "loss = 0.099729     [12800\\39687]\n",
      "loss = 0.131835     [16000\\39687]\n",
      "loss = 0.132473     [19200\\39687]\n",
      "loss = 0.123090     [22400\\39687]\n",
      "loss = 0.079678     [25600\\39687]\n",
      "loss = 0.130449     [28800\\39687]\n",
      "loss = 0.170949     [32000\\39687]\n",
      "loss = 0.159267     [35200\\39687]\n",
      "loss = 0.175545     [38400\\39687]\n",
      "\n",
      "Epoch: 16-----------------------------------------\n",
      "loss = 0.075392     [    0\\39687]\n",
      "loss = 0.087126     [ 3200\\39687]\n",
      "loss = 0.116816     [ 6400\\39687]\n",
      "loss = 0.073438     [ 9600\\39687]\n",
      "loss = 0.109832     [12800\\39687]\n",
      "loss = 0.106252     [16000\\39687]\n",
      "loss = 0.134814     [19200\\39687]\n",
      "loss = 0.117367     [22400\\39687]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.122340     [25600\\39687]\n",
      "loss = 0.102624     [28800\\39687]\n",
      "loss = 0.175801     [32000\\39687]\n",
      "loss = 0.136267     [35200\\39687]\n",
      "loss = 0.167777     [38400\\39687]\n",
      "\n",
      "Epoch: 17-----------------------------------------\n",
      "loss = 0.058874     [    0\\39687]\n",
      "loss = 0.082924     [ 3200\\39687]\n",
      "loss = 0.106420     [ 6400\\39687]\n",
      "loss = 0.118103     [ 9600\\39687]\n",
      "loss = 0.093098     [12800\\39687]\n",
      "loss = 0.085960     [16000\\39687]\n",
      "loss = 0.077900     [19200\\39687]\n",
      "loss = 0.106544     [22400\\39687]\n",
      "loss = 0.125715     [25600\\39687]\n",
      "loss = 0.148488     [28800\\39687]\n",
      "loss = 0.149465     [32000\\39687]\n",
      "loss = 0.144113     [35200\\39687]\n",
      "loss = 0.159174     [38400\\39687]\n",
      "\n",
      "Epoch: 18-----------------------------------------\n",
      "loss = 0.095960     [    0\\39687]\n",
      "loss = 0.070018     [ 3200\\39687]\n",
      "loss = 0.088007     [ 6400\\39687]\n",
      "loss = 0.069357     [ 9600\\39687]\n",
      "loss = 0.104755     [12800\\39687]\n",
      "loss = 0.101573     [16000\\39687]\n",
      "loss = 0.068733     [19200\\39687]\n",
      "loss = 0.105083     [22400\\39687]\n",
      "loss = 0.126914     [25600\\39687]\n",
      "loss = 0.147839     [28800\\39687]\n",
      "loss = 0.154602     [32000\\39687]\n",
      "loss = 0.149762     [35200\\39687]\n",
      "loss = 0.106328     [38400\\39687]\n",
      "\n",
      "Epoch: 19-----------------------------------------\n",
      "loss = 0.084893     [    0\\39687]\n",
      "loss = 0.084281     [ 3200\\39687]\n",
      "loss = 0.067114     [ 6400\\39687]\n",
      "loss = 0.079212     [ 9600\\39687]\n",
      "loss = 0.084406     [12800\\39687]\n",
      "loss = 0.092578     [16000\\39687]\n",
      "loss = 0.073332     [19200\\39687]\n",
      "loss = 0.113711     [22400\\39687]\n",
      "loss = 0.114602     [25600\\39687]\n",
      "loss = 0.113742     [28800\\39687]\n",
      "loss = 0.135111     [32000\\39687]\n",
      "loss = 0.117356     [35200\\39687]\n",
      "loss = 0.130227     [38400\\39687]\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "for k in range(20):\n",
    "    print(f'\\nEpoch: {k}-----------------------------------------')\n",
    "    model_gru.train()\n",
    "    train_loop(model_gru, optimizer_gru, loss_func, train_dataloader, writer_gru, k, 'GRU')\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fe6a4222",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 8892 (pid 4756), started 1:54:59 ago. (Use '!kill 4756' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-de3d89f11983309b\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-de3d89f11983309b\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 8892;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "writer_gru.flush()\n",
    "writer_gru.close() \n",
    "writer_lstm.flush()\n",
    "writer_lstm.close() \n",
    "#%load_ext tensorboard\n",
    "%tensorboard --logdir='runs' --port=8892 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "126c65b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Generate_Verse(model, name):\n",
    "    x, y = Test[np.random.randint(0, len(Test))]\n",
    "    x.unsqueeze_(0)\n",
    "    y.unsqueeze_(0)\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    word_idx = x[:, 1:]\n",
    "    siz = y.shape\n",
    "    word_embed = model.embedding(word_idx)\n",
    "    if name == 'lstm':\n",
    "        Out, (hk, ck) = model.lstm(word_embed)\n",
    "    else:\n",
    "        out, hk = model.gru(word_embed)\n",
    "    #print(Out.shape)\n",
    "    pred_idx = torch.zeros_like(y)\n",
    "    w_idx = x[:, 0].unsqueeze(-1)\n",
    "    #hk, ck = hout, cout\n",
    "    #print(hk.shape, ck.shape)\n",
    "    #print(w_idx.shape)\n",
    "    for k in range(max(Len_Verse)):\n",
    "        w_embed = model.embedding(w_idx)\n",
    "        if name == 'lstm':\n",
    "            outk, (hk, ck) = model.lstm(w_embed, (hk, ck))\n",
    "        else:\n",
    "            outk, hk = model.gru(w_embed, hk)\n",
    "        logitk = model.linear(outk)\n",
    "        w_idx = torch.argmax(logitk, dim = -1)\n",
    "        #print('fnjgjf', w_embed.shape)\n",
    "        pred_idx[:, k] = w_idx.squeeze()\n",
    "        #print(w_idx.shape)\n",
    "        #print(amoerfan)\n",
    "    x.squeeze_()\n",
    "    y.squeeze_()\n",
    "    pred_idx.squeeze_()\n",
    "    first_verse = [Dict[p] for p in x.tolist()]\n",
    "    true_verse = [Dict[p] for p in y.tolist()]\n",
    "    pred_verse = [Dict[p] for p in pred_idx.tolist()]\n",
    "    #print(pred_verse)\n",
    "    first_verse = [val for val in first_verse if val != '<خالی>']\n",
    "    true_verse = [val for val in true_verse if val != '<خالی>']\n",
    "    first_verse = [val for val in first_verse if val != '<شروع>']\n",
    "    true_verse = [val for val in true_verse if val != '<شروع>']\n",
    "    first_verse = [val for val in first_verse if val != '.']\n",
    "    true_verse = [val for val in true_verse if val != '.']\n",
    "    pred_verse = [val for val in pred_verse if val != '<خالی>']\n",
    "    pred_verse = [val for val in pred_verse if val != '<شروع>']\n",
    "    pred_verse = [val for val in pred_verse if val != '.']\n",
    "\n",
    "    str_first = ''\n",
    "    str_true = ''\n",
    "    str_pred = ''\n",
    "    for string in first_verse:\n",
    "        str_first += string + ' '\n",
    "    for string in true_verse:\n",
    "        str_true += string + ' '\n",
    "    for string in pred_verse:\n",
    "        str_pred += string + ' '\n",
    "    print(str_first, str_true, str_pred, sep = '\\t\\t')\n",
    "    #print(str_true)\n",
    "    #print(str_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07b8567",
   "metadata": {},
   "source": [
    "We show some predictions of the \"LSTM\" model on the test dataset. we predict the second stanza when we apply the first one to the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "846dae3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "مصرع اول\t\t\t\tمصرع دوم\t\t\t\tمصرع تولید شده با شبکه\n",
      "\n",
      "\n",
      "به آوردگه گشت و نیزه بگاشت \t\tچو لختی بگردید نیزه بداشت \t\tکه بد مرز توران ترا یار شیر \n",
      "\n",
      "\n",
      "بدانست هومان که آمد سوار \t\tهمه گرزور بود و شمشیردار \t\tسوی چاره ها سوی دستان سوار \n",
      "\n",
      "\n",
      "یکی گفت زان فیلسوفان به شاه \t\tکه بر ژرف دریا ترا نیست راه \t\tگزین کرد زان دانش و رای شاه \n",
      "\n",
      "\n",
      "فرستاده گفت ای خردمند مرد \t\tمگر داند او گرد دانا مگرد \t\tمرا بیهده نیست این گفت وگوی \n",
      "\n",
      "\n",
      "هما راه جستیم و بگریختیم \t\tبه دام بلا بر نیاویختیم \t\tنه اندر خور کار جایی نه دشت \n",
      "\n",
      "\n",
      "چشیده بسی از جهان شور و تلخ \t\tبیاری گستهم نوذر ببلخ \t\tاگر روز باشدت نیست ساز \n",
      "\n",
      "\n",
      "کزان بوم خیزد سپهبد چوتو \t\tفزون آفریناد ایزد چو تو \t\tچنان دان که کشتی ازو بار و یار \n",
      "\n",
      "\n",
      "بدو گفت بهرام کای بدکنش \t\tنزیبد همی بر تو جز سرزنش \t\tدل و چشم دشمن به خم هوا \n",
      "\n",
      "\n",
      "همه پهلوانان روی زمین \t\tبرو یکسره خواندند آفرین \t\tمنوچهر را خواندند آفرین \n",
      "\n",
      "\n",
      "چه با مهد زرین به دیبای چین \t\tبگوهر بیاراسته همچنین \t\tبرو آفرین کرد و پیروز بخت \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Showing the LSTM model on the \"Test dataset\"\n",
    "print('مصرع اول', 'مصرع دوم', 'مصرع تولید شده با شبکه', sep = '\\t\\t\\t\\t')\n",
    "print('\\n')\n",
    "for k in range(10):\n",
    "    Generate_Verse(model_lstm, 'lstm')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c589737",
   "metadata": {},
   "source": [
    "We show some predictions of the \"GRU\" model on the test dataset. we predict the second stanza when we apply the first one to the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ef7817e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "مصرع اول\t\t\t\tمصرع دوم\t\t\t\tمصرع تولید شده با شبکه\n",
      "\n",
      "\n",
      "چو روی تخوار او فروزان بدید \t\tاز اندوه چندان دلش بردمید \t\tزمین را ببوسید و شد ناپدید \n",
      "\n",
      "\n",
      "به فر تو گفتا همه بهتریست \t\tابا تو همه رنج رامشگریست \t\tبگویند کاین خویشتن را بخوان \n",
      "\n",
      "\n",
      "سپه کوه تا کوه صف برکشید \t\tپی مور شد بر زمین ناپدید \t\tدمان و دنان برگرفتند روی \n",
      "\n",
      "\n",
      "که خود پیش او دم توان زد درشت \t\tورا گردش اختر بد بکشت \t\tبب و دل باز بینند روی \n",
      "\n",
      "\n",
      "گر ایدونک گشتاسپ از روی بخت \t\tنیابد همی سیری از تاج و تخت \t\tبدو تاج و تخت و نه تاج و کلاه \n",
      "\n",
      "\n",
      "فریبرز گفت آنچ خسرو بگفت \t\tکه با جان پاکش خرد باد جفت \t\tکه او را جز ایدر نباید نهفت \n",
      "\n",
      "\n",
      "بیامد برخش اندر آورد پای \t\tکمر بست و پوشید رومی قبای \t\tبه دستوری بازگشتن به جای \n",
      "\n",
      "\n",
      "به پیش بزرگان ستایش کنیم \t\tهمان پیش یزدان نیایش کنیم \t\tنهفته به بازی نیایش کنیم \n",
      "\n",
      "\n",
      "به نزدیک یزدان ز تخمی که کشت \t\tبه باید بپاداش خرم بهشت \t\tکه او را نباشد کسی او چه داشت \n",
      "\n",
      "\n",
      "هم ان کین هرمز کنم خواستار \t\tدگرکاندر ایران منم شهریار \t\tکه بر من یکی روزگار آوری \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('مصرع اول', 'مصرع دوم', 'مصرع تولید شده با شبکه', sep = '\\t\\t\\t\\t')\n",
    "print('\\n')\n",
    "for k in range(10):\n",
    "    Generate_Verse(model_gru, 'gru')\n",
    "    print('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
